{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom dataset class\n",
    "class FashionMNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file) # read data from csv file as a pandas dataframe\n",
    "        self.transform = transform # initial transfrom\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = Image.fromarray(self.data_frame.iloc[idx, 1:].values.reshape(28, 28).astype(np.uint8))\n",
    "        \n",
    "        label = int(self.data_frame.iloc[idx, 0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.AutoAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4850, 0.4560, 0.4060], std=[0.2290, 0.2240, 0.2250])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4850, 0.4560, 0.4060], std=[0.2290, 0.2240, 0.2250])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dataset and dataloader\n",
    "train_path = 'dataset/fashion-mnist_train.csv'\n",
    "test_path = 'dataset/fashion-mnist_test.csv'\n",
    "\n",
    "train_data = FashionMNISTDataset(csv_file=train_path, transform=train_transform)\n",
    "test_data = FashionMNISTDataset(csv_file=test_path, transform=test_transform)\n",
    "testLen = int(len(test_data) * 0.5)\n",
    "valLen = len(test_data) - testLen\n",
    "test_data, val_data = random_split(test_data, [testLen, valLen])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\summercourse\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\summercourse\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "#choose a model\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "#choose a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), weight_decay=0.001, lr=0.0001)\n",
    "\n",
    "#move model to cuda/cpu\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80, Training Loss: 0.6486, Training Accuracy: 0.7620\n",
      "Epoch 2/80, Training Loss: 0.4644, Training Accuracy: 0.8257\n",
      "Epoch 3/80, Training Loss: 0.4140, Training Accuracy: 0.8464\n",
      "Epoch 4/80, Training Loss: 0.3767, Training Accuracy: 0.8593\n",
      "Epoch 5/80, Training Loss: 0.3549, Training Accuracy: 0.8680\n",
      "Validation Loss: 0.2732, Validation Accuracy: 0.8970\n",
      "Epoch 6/80, Training Loss: 0.3336, Training Accuracy: 0.8759\n",
      "Epoch 7/80, Training Loss: 0.3167, Training Accuracy: 0.8810\n",
      "Epoch 8/80, Training Loss: 0.3057, Training Accuracy: 0.8858\n",
      "Epoch 9/80, Training Loss: 0.2938, Training Accuracy: 0.8897\n",
      "Epoch 10/80, Training Loss: 0.2841, Training Accuracy: 0.8941\n",
      "Validation Loss: 0.2382, Validation Accuracy: 0.9144\n",
      "Epoch 11/80, Training Loss: 0.2746, Training Accuracy: 0.8974\n",
      "Epoch 12/80, Training Loss: 0.2638, Training Accuracy: 0.9014\n",
      "Epoch 13/80, Training Loss: 0.2592, Training Accuracy: 0.9027\n",
      "Epoch 14/80, Training Loss: 0.2541, Training Accuracy: 0.9049\n",
      "Epoch 15/80, Training Loss: 0.2474, Training Accuracy: 0.9075\n",
      "Validation Loss: 0.2207, Validation Accuracy: 0.9162\n",
      "Epoch 16/80, Training Loss: 0.2422, Training Accuracy: 0.9093\n",
      "Epoch 17/80, Training Loss: 0.2347, Training Accuracy: 0.9115\n",
      "Epoch 18/80, Training Loss: 0.2289, Training Accuracy: 0.9143\n",
      "Epoch 19/80, Training Loss: 0.2256, Training Accuracy: 0.9156\n",
      "Epoch 20/80, Training Loss: 0.2172, Training Accuracy: 0.9196\n",
      "Validation Loss: 0.2255, Validation Accuracy: 0.9218\n",
      "Epoch 21/80, Training Loss: 0.2101, Training Accuracy: 0.9201\n",
      "Epoch 22/80, Training Loss: 0.2058, Training Accuracy: 0.9223\n",
      "Epoch 23/80, Training Loss: 0.2050, Training Accuracy: 0.9227\n",
      "Epoch 24/80, Training Loss: 0.1982, Training Accuracy: 0.9259\n",
      "Epoch 25/80, Training Loss: 0.1947, Training Accuracy: 0.9270\n",
      "Validation Loss: 0.2102, Validation Accuracy: 0.9272\n",
      "Epoch 26/80, Training Loss: 0.1932, Training Accuracy: 0.9279\n",
      "Epoch 27/80, Training Loss: 0.1887, Training Accuracy: 0.9285\n",
      "Epoch 28/80, Training Loss: 0.1829, Training Accuracy: 0.9313\n",
      "Epoch 29/80, Training Loss: 0.1799, Training Accuracy: 0.9326\n",
      "Epoch 30/80, Training Loss: 0.1766, Training Accuracy: 0.9351\n",
      "Validation Loss: 0.2173, Validation Accuracy: 0.9260\n",
      "Epoch 31/80, Training Loss: 0.1738, Training Accuracy: 0.9367\n",
      "Epoch 32/80, Training Loss: 0.1709, Training Accuracy: 0.9370\n",
      "Epoch 33/80, Training Loss: 0.1695, Training Accuracy: 0.9372\n",
      "Epoch 34/80, Training Loss: 0.1639, Training Accuracy: 0.9396\n",
      "Epoch 35/80, Training Loss: 0.1639, Training Accuracy: 0.9398\n",
      "Validation Loss: 0.2430, Validation Accuracy: 0.9226\n",
      "Epoch 36/80, Training Loss: 0.1622, Training Accuracy: 0.9391\n",
      "Epoch 37/80, Training Loss: 0.1575, Training Accuracy: 0.9407\n",
      "Epoch 38/80, Training Loss: 0.1549, Training Accuracy: 0.9431\n",
      "Epoch 39/80, Training Loss: 0.1536, Training Accuracy: 0.9442\n",
      "Epoch 40/80, Training Loss: 0.1544, Training Accuracy: 0.9424\n",
      "Validation Loss: 0.2222, Validation Accuracy: 0.9256\n",
      "Epoch 41/80, Training Loss: 0.1511, Training Accuracy: 0.9451\n",
      "Epoch 42/80, Training Loss: 0.1451, Training Accuracy: 0.9452\n",
      "Epoch 43/80, Training Loss: 0.1420, Training Accuracy: 0.9479\n",
      "Epoch 44/80, Training Loss: 0.1427, Training Accuracy: 0.9467\n",
      "Epoch 45/80, Training Loss: 0.1427, Training Accuracy: 0.9480\n",
      "Validation Loss: 0.2532, Validation Accuracy: 0.9264\n",
      "Epoch 46/80, Training Loss: 0.1398, Training Accuracy: 0.9479\n",
      "Epoch 47/80, Training Loss: 0.1398, Training Accuracy: 0.9489\n",
      "Epoch 48/80, Training Loss: 0.1346, Training Accuracy: 0.9493\n",
      "Epoch 49/80, Training Loss: 0.1362, Training Accuracy: 0.9510\n",
      "Epoch 50/80, Training Loss: 0.1333, Training Accuracy: 0.9513\n",
      "Validation Loss: 0.2443, Validation Accuracy: 0.9258\n",
      "Epoch 51/80, Training Loss: 0.1299, Training Accuracy: 0.9523\n",
      "Epoch 52/80, Training Loss: 0.1319, Training Accuracy: 0.9514\n",
      "Epoch 53/80, Training Loss: 0.1274, Training Accuracy: 0.9537\n",
      "Epoch 54/80, Training Loss: 0.1295, Training Accuracy: 0.9524\n",
      "Epoch 55/80, Training Loss: 0.1258, Training Accuracy: 0.9540\n",
      "Validation Loss: 0.2634, Validation Accuracy: 0.9262\n",
      "Epoch 56/80, Training Loss: 0.1235, Training Accuracy: 0.9550\n",
      "Epoch 57/80, Training Loss: 0.1235, Training Accuracy: 0.9552\n",
      "Epoch 58/80, Training Loss: 0.1233, Training Accuracy: 0.9548\n",
      "Epoch 59/80, Training Loss: 0.1210, Training Accuracy: 0.9561\n",
      "Epoch 60/80, Training Loss: 0.1197, Training Accuracy: 0.9561\n",
      "Validation Loss: 0.2549, Validation Accuracy: 0.9280\n",
      "Epoch 61/80, Training Loss: 0.1208, Training Accuracy: 0.9551\n",
      "Epoch 62/80, Training Loss: 0.1163, Training Accuracy: 0.9569\n",
      "Epoch 63/80, Training Loss: 0.1161, Training Accuracy: 0.9569\n",
      "Epoch 64/80, Training Loss: 0.1135, Training Accuracy: 0.9588\n",
      "Epoch 65/80, Training Loss: 0.1169, Training Accuracy: 0.9568\n",
      "Validation Loss: 0.2685, Validation Accuracy: 0.9260\n",
      "Epoch 66/80, Training Loss: 0.1155, Training Accuracy: 0.9572\n",
      "Epoch 67/80, Training Loss: 0.1148, Training Accuracy: 0.9575\n",
      "Epoch 68/80, Training Loss: 0.1124, Training Accuracy: 0.9584\n",
      "Epoch 69/80, Training Loss: 0.1126, Training Accuracy: 0.9595\n",
      "Epoch 70/80, Training Loss: 0.1109, Training Accuracy: 0.9596\n",
      "Validation Loss: 0.2619, Validation Accuracy: 0.9266\n",
      "Epoch 71/80, Training Loss: 0.1085, Training Accuracy: 0.9606\n",
      "Epoch 72/80, Training Loss: 0.1085, Training Accuracy: 0.9597\n",
      "Epoch 73/80, Training Loss: 0.1092, Training Accuracy: 0.9601\n",
      "Epoch 74/80, Training Loss: 0.1102, Training Accuracy: 0.9602\n",
      "Epoch 75/80, Training Loss: 0.1061, Training Accuracy: 0.9609\n",
      "Validation Loss: 0.2816, Validation Accuracy: 0.9244\n",
      "Epoch 76/80, Training Loss: 0.1064, Training Accuracy: 0.9610\n",
      "Epoch 77/80, Training Loss: 0.1066, Training Accuracy: 0.9598\n",
      "Epoch 78/80, Training Loss: 0.1040, Training Accuracy: 0.9614\n",
      "Epoch 79/80, Training Loss: 0.1036, Training Accuracy: 0.9623\n",
      "Epoch 80/80, Training Loss: 0.1043, Training Accuracy: 0.9616\n",
      "Validation Loss: 0.2745, Validation Accuracy: 0.9284\n"
     ]
    }
   ],
   "source": [
    "#training section\n",
    "num_epochs = 80\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    #evaluate on validation set every epoch\n",
    "    if epoch % 5 == 4:\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            val_loss = running_val_loss / len(val_loader.dataset)\n",
    "            val_accuracy = correct_val / total_val\n",
    "\n",
    "            if val_accuracy > best_accuracy:\n",
    "                # Save model weights\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "                best_accuracy = val_accuracy\n",
    "\n",
    "            print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mingyiao\\AppData\\Local\\Temp\\ipykernel_18948\\1132812897.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss: 0.2904, Testing Accuracy: 0.9238\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "#evaluate on testing set every epoch\n",
    "model.eval()\n",
    "running_test_loss = 0.0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_test_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss = running_test_loss / len(test_loader.dataset)\n",
    "test_accuracy = correct_test / total_test\n",
    "\n",
    "print(f'Testing Loss: {test_loss:.4f}, Testing Accuracy: {test_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summercourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
